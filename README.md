# SkyGuard: Human, AI Security Simulation [![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://skyguard, project, 2025.streamlit.app/) ![Python](https://img.shields.io/badge/Python, 3.9%2B, blue) ![Status](https://img.shields.io/badge/Status, Live, success) ## Project Overview **SkyGuard** is a Python, based exploratory tool to measure **Automation Bias**, **Trust Calibration**, and **Cognitive Load** in Human, AI Teaming situations. The simulation recreates an airport baggage X, Ray screening task under very high stakes. It is the main vehicle for collecting data for the writer's Master's Dissertation: *"The effect of imperfect AI assistance on human vigilance in security screening: a study."* **[Live Demo](https://skyguard, project, 2025.streamlit.app/)** ## Research Objectives The simulation is intended to track and analyze the following measures: 1. **Reaction Time:** Does AI assistance accelerate or delay decision, making (Cost of Verification)? 2. **Accuracy:** Does AI presence help the human to reduce errors or does it lead to "blind compliance"? 3. **Automation Bias:** What is the reaction of the operators when the AI provides a wrong answer on purpose? ## Experimental Design The experiment implements a **Within, Subjects Design** where participants experience two different conditions: | Condition | Description | | :, | :, | | ** Manual Mode** | The participant is on his/her own. They have to find visually the threat items (Guns, Knives, Bombs) in the luggage without having any help. | | ** AI Assist Mode** | A simulated AI agent supports the user. The AI sends a text message (Clear/Threat) with a confidence score. |
